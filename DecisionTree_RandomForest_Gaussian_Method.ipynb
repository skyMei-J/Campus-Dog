{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyMei-J/Campus-Dog/blob/main/DecisionTree_RandomForest_Gaussian_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A10lmWMRRA-I"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.checkpoint import checkpoint\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOCBDV9FRA-Q"
      },
      "source": [
        "# decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li4edA_oRA-Q",
        "outputId": "c2497ecd-fb5b-44bb-e511-0bf40451c9e5"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from gluoncv import model_zoo, data, utils\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from skimage import exposure\n",
        "from skimage import feature\n",
        "from imutils import paths\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "net = model_zoo.get_model('yolo3_darknet53_voc', pretrained=True)\n",
        "def cutImage(imageP):\n",
        "    print(imageP)\n",
        "    x, img = data.transforms.presets.yolo.load_test(imageP, short=512)\n",
        "\n",
        "    class_IDs, scores, bounding_boxs = net(x)\n",
        "    ax = utils.viz.plot_bbox(img, bounding_boxs[0], scores[0],class_IDs[0], class_names=net.classes)\n",
        "    bbbox = bounding_boxs[0][0].astype(int).asnumpy()\n",
        "\n",
        "    (x,y,w,h) = bbbox\n",
        "    if x<0 :\n",
        "        x=0\n",
        "    if y<0:\n",
        "        y=0\n",
        "    img = img[y:y+h,x:x+w]\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    return img\n",
        "\n",
        "\n",
        "#####################################################\n",
        "\n",
        "labels = []\n",
        "count = int(0)\n",
        "data = np.empty((0, 6),float)\n",
        "cutted_data = np.empty((0, 6),float)\n",
        "entries = os.listdir(\"train\")\n",
        "output = pd.DataFrame({'Mean_Blue': [], 'Mean_Green': [], 'Mean_Red': [], 'Standard_Blue': [], 'Standard_Green': [], 'Standard_Red': [], 'Label': []})\n",
        "cutted_output = pd.DataFrame({'Mean_Blue': [], 'Mean_Green': [], 'Mean_Red': [], 'Standard_Blue': [], 'Standard_Green': [], 'Standard_Red': [], 'Label': []})\n",
        "allimage_list = []\n",
        "total_data_num = 0\n",
        "for dirPath in entries:\n",
        "    allimage = glob.glob( \"train/\"+dirPath +\"/*.jpg\")\n",
        "    for i in allimage:\n",
        "        allimage_list.append(i)\n",
        "\n",
        "for dirPath in entries:\n",
        "    allimage = glob.glob( \"train/\"+dirPath +\"/*.JPG\")\n",
        "    for i in allimage:\n",
        "        allimage_list.append(i)\n",
        "\n",
        "total_data_num = len(allimage_list)\n",
        "temp_data_num = total_data_num\n",
        "# print(\"total_data_num: \", total_data_num)\n",
        "\n",
        "while temp_data_num > total_data_num * 0.3:\n",
        "\n",
        "    #read path\n",
        "    imagePath = allimage_list.pop(random.randint(0, temp_data_num-1))\n",
        "    temp_data_num = temp_data_num - 1\n",
        "    # print(\"temp_data_num: \", temp_data_num)\n",
        "    #make = label\n",
        "    make = imagePath.split(\"/\")[-2]\n",
        "\n",
        "    ########## original ##########\n",
        "    image = cv2.imread(imagePath)\n",
        "    # print(imagePath)\n",
        "    (means, stds) = cv2.meanStdDev(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))\n",
        "    result = pd.DataFrame({'Mean_Blue': [means[0]], 'Mean_Green': [means[1]], 'Mean_Red': [means[2]], 'Standard_Blue': [stds[0]], 'Standard_Green': [stds[1]], 'Standard_Red': [stds[2]], 'Label': [make]})\n",
        "    output = pd.concat([output, result], axis = 0)\n",
        "\n",
        "    x_data = []\n",
        "    for i in means:\n",
        "        x_data.append(float(i))\n",
        "    for i in stds:\n",
        "        x_data.append(float(i))\n",
        "    x_data = np.array(x_data)\n",
        "\n",
        "    data = np.vstack((data, x_data))\n",
        "\n",
        "\n",
        "    ########## cutted ##########\n",
        "    # print(imagePath,'############################')\n",
        "    # plt.imshow(image)\n",
        "    # plt.show()\n",
        "    # cutted_image = cutImage(imagePath)\n",
        "    # (means, stds) = cv2.meanStdDev(cv2.cvtColor(cutted_image, cv2.COLOR_BGR2HSV))\n",
        "    # cutted_result = pd.DataFrame({'Mean_Blue': [means[0]], 'Mean_Green': [means[1]], 'Mean_Red': [means[2]], 'Standard_Blue': [stds[0]], 'Standard_Green': [stds[1]], 'Standard_Red': [stds[2]], 'Label': [make]})\n",
        "    # cutted_output = pd.concat([output, result], axis = 0)\n",
        "\n",
        "    # cutted_x_data = []\n",
        "    # for i in means:\n",
        "        # cutted_x_data.append(float(i))\n",
        "    # for i in stds:\n",
        "        # cutted_x_data.append(float(i))\n",
        "    # cutted_x_data = np.array(cutted_x_data)\n",
        "\n",
        "    # cutted_data = np.vstack((cutted_data, cutted_x_data))\n",
        "\n",
        "    #push label into label list\n",
        "    labels.append(make)\n",
        "\n",
        "data = np.array(data)\n",
        "cutted_data = np.array(cutted_data)\n",
        "\n",
        "clf = ensemble.RandomForestClassifier(n_estimators = 99)\n",
        "clf = clf.fit(data, labels)\n",
        "\n",
        "# cutted_clf = ensemble.RandomForestClassifier(n_estimators = 99)\n",
        "# cutted_clf = cutted_clf.fit(cutted_data, labels)\n",
        "\n",
        "correct = 0\n",
        "cutted_correct = 0\n",
        "num_test_data = 0\n",
        "\n",
        "tstart = time.time()\n",
        "\n",
        "while temp_data_num:\n",
        "\n",
        "    temp_data_num = temp_data_num - 1\n",
        "    # print(\"temp_data_num: \", temp_data_num)\n",
        "    imagePath = allimage_list.pop()\n",
        "    make = imagePath.split(\"/\")[-2]\n",
        "    num_test_data = num_test_data + 1\n",
        "\n",
        "    ########## original ##########\n",
        "    image = cv2.imread(imagePath)\n",
        "    (means, stds) = cv2.meanStdDev(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))\n",
        "    result = pd.DataFrame({'Mean_Blue': [means[0]], 'Mean_Green': [means[1]], 'Mean_Red': [means[2]], 'Standard_Blue': [stds[0]], 'Standard_Green': [stds[1]], 'Standard_Red': [stds[2]], 'Label': [make]})\n",
        "    output = pd.concat([output, result], axis = 0)\n",
        "\n",
        "    x_data = []\n",
        "    for i in means:\n",
        "        x_data.append(float(i))\n",
        "    for i in stds:\n",
        "        x_data.append(float(i))\n",
        "    x_data = np.array(x_data)\n",
        "    x_data = x_data.reshape(1,-1)\n",
        "    pred = clf.predict(x_data)\n",
        "\n",
        "    ########## cutted ##########\n",
        "    # cutted_image = cutImage(imagePath)\n",
        "    # (means, stds) = cv2.meanStdDev(cv2.cvtColor(cutted_image, cv2.COLOR_BGR2HSV))\n",
        "    # cutted_result = pd.DataFrame({'Mean_Blue': [means[0]], 'Mean_Green': [means[1]], 'Mean_Red': [means[2]], 'Standard_Blue': [stds[0]], 'Standard_Green': [stds[1]], 'Standard_Red': [stds[2]], 'Label': [make]})\n",
        "    # cutted_output = pd.concat([output, result], axis = 0)\n",
        "\n",
        "    # cutted_x_data = []\n",
        "    # for i in means:\n",
        "        # cutted_x_data.append(float(i))\n",
        "    # for i in stds:\n",
        "        # cutted_x_data.append(float(i))\n",
        "    # cutted_x_data = np.array(cutted_x_data)\n",
        "    # cutted_x_data = x_data.reshape(1,-1)\n",
        "    # cutted_pred = cutted_clf.predict(cutted_x_data)\n",
        "\n",
        "\n",
        "    #original result\t\n",
        "    # print(\"original\")\n",
        "    # print(\"target: \", make)\n",
        "    # print(\"predict: \", pred)\n",
        "\n",
        "    if make == pred:\n",
        "        correct = correct + 1\n",
        "\n",
        "    #cutted result\t\n",
        "    # print(\"cutted\")\n",
        "    # print(\"target: \", make)\n",
        "    # print(\"predict: \", cutted_pred)\n",
        "\n",
        "    # if make == cutted_pred:\n",
        "        # cutted_correct = cutted_correct + 1\n",
        "\n",
        "print(\"Original\")\n",
        "print(correct/num_test_data)\n",
        "# print(\"Cutted\")\n",
        "# print(cutted_correct/num_test_data)\n",
        "\n",
        "tend = time.time()\n",
        "\n",
        "print(\"time : \", total_data_num/(tend - tstart))\n",
        "\n",
        "output.to_csv('Output.csv')\n",
        "fig1 = plt.figure()\n",
        "ax1 = Axes3D(fig1)\n",
        "ax1.set_xlim3d(output['Mean_Blue'].min(), output['Mean_Blue'].max())\n",
        "ax1.set_ylim3d(output['Mean_Green'].min(), output['Mean_Green'].max())\n",
        "ax1.set_zlim3d(output['Mean_Red'].min(), output['Mean_Red'].max())\n",
        "for i in range(output.shape[0]):\n",
        "    if output.iloc[i]['Label'] == 'white':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'ro')\n",
        "    elif output.iloc[i]['Label'] == 'steak':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'go')\n",
        "    elif output.iloc[i]['Label'] == 'curl':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'bo')\n",
        "    elif output.iloc[i]['Label'] == 'dressed_long_leg':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'co')\n",
        "    elif output.iloc[i]['Label'] == 'long leg':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'mo')\n",
        "    else:\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'ko')\n",
        "plt.show()\n",
        "\n",
        "fig2 = plt.figure()\n",
        "ax2 = Axes3D(fig2)\n",
        "ax2.set_xlim3d(output['Standard_Blue'].min(), output['Standard_Blue'].max())\n",
        "ax2.set_ylim3d(output['Standard_Green'].min(), output['Standard_Green'].max())\n",
        "ax2.set_zlim3d(output['Standard_Red'].min(), output['Standard_Red'].max())\n",
        "for i in range(output.shape[0]):\n",
        "    if output.iloc[i]['Label'] == 'white':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'ro')\n",
        "    elif output.iloc[i]['Label'] == 'steak':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'go')\n",
        "    elif output.iloc[i]['Label'] == 'curl':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'bo')\n",
        "    elif output.iloc[i]['Label'] == 'dressed_long_leg':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'co')\n",
        "    elif output.iloc[i]['Label'] == 'long leg':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'mo')\n",
        "    else:\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'ko')\n",
        "plt.show()\n",
        "\n",
        "# cutted_output.to_csv('Cutted_Output.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-54e6e6058c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mcutted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Mean_Blue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean_Green'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean_Red'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Blue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Green'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Red'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mcutted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Mean_Blue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean_Green'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean_Red'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Blue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Green'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Red'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J50MW7T8RA-Q"
      },
      "source": [
        "# random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obypCxF_RA-Q",
        "outputId": "3c734746-75d0-4467-adfa-8555de82bd1c"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from gluoncv import model_zoo, data, utils\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from skimage import exposure\n",
        "from skimage import feature\n",
        "from imutils import paths\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "net = model_zoo.get_model('yolo3_darknet53_voc', pretrained=True)\n",
        "def cutImage(imageP):\n",
        "    print(imageP)\n",
        "    x, img = data.transforms.presets.yolo.load_test(imageP, short=512)\n",
        "\n",
        "    class_IDs, scores, bounding_boxs = net(x)\n",
        "    ax = utils.viz.plot_bbox(img, bounding_boxs[0], scores[0],class_IDs[0], class_names=net.classes)\n",
        "    bbbox = bounding_boxs[0][0].astype(int).asnumpy()\n",
        "\n",
        "    (x,y,w,h) = bbbox\n",
        "    if x<0 :\n",
        "        x=0\n",
        "    if y<0:\n",
        "        y=0\n",
        "    img = img[y:y+h,x:x+w]\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    return img\n",
        "\n",
        "\n",
        "#####################################################\n",
        "\n",
        "labels = []\n",
        "count = int(0)\n",
        "data = np.empty((0, 6),float)\n",
        "cutted_data = np.empty((0, 6),float)\n",
        "entries = os.listdir(\"train\")\n",
        "output = pd.DataFrame({'Mean_Blue': [], 'Mean_Green': [], 'Mean_Red': [], 'Standard_Blue': [], 'Standard_Green': [], 'Standard_Red': [], 'Label': []})\n",
        "cutted_output = pd.DataFrame({'Mean_Blue': [], 'Mean_Green': [], 'Mean_Red': [], 'Standard_Blue': [], 'Standard_Green': [], 'Standard_Red': [], 'Label': []})\n",
        "allimage_list = []\n",
        "total_data_num = 0\n",
        "for dirPath in entries:\n",
        "    allimage = glob.glob( \"train/\"+dirPath +\"/*.jpg\")\n",
        "    for i in allimage:\n",
        "        allimage_list.append(i)\n",
        "\n",
        "for dirPath in entries:\n",
        "    allimage = glob.glob( \"train/\"+dirPath +\"/*.JPG\")\n",
        "    for i in allimage:\n",
        "        allimage_list.append(i)\n",
        "\n",
        "total_data_num = len(allimage_list)\n",
        "temp_data_num = total_data_num\n",
        "# print(\"total_data_num: \", total_data_num)\n",
        "\n",
        "while temp_data_num > total_data_num * 0.3:\n",
        "\n",
        "    #read path\n",
        "    imagePath = allimage_list.pop(random.randint(0, temp_data_num-1))\n",
        "    temp_data_num = temp_data_num - 1\n",
        "    # print(\"temp_data_num: \", temp_data_num)\n",
        "    #make = label\n",
        "    make = imagePath.split(\"/\")[-2]\n",
        "\n",
        "    ########## original ##########\n",
        "    image = cv2.imread(imagePath)\n",
        "    # print(imagePath)\n",
        "    (means, stds) = cv2.meanStdDev(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))\n",
        "    result = pd.DataFrame({'Mean_Blue': [means[0]], 'Mean_Green': [means[1]], 'Mean_Red': [means[2]], 'Standard_Blue': [stds[0]], 'Standard_Green': [stds[1]], 'Standard_Red': [stds[2]], 'Label': [make]})\n",
        "    output = pd.concat([output, result], axis = 0)\n",
        "\n",
        "    x_data = []\n",
        "    for i in means:\n",
        "        x_data.append(float(i))\n",
        "    for i in stds:\n",
        "        x_data.append(float(i))\n",
        "    x_data = np.array(x_data)\n",
        "\n",
        "    data = np.vstack((data, x_data))\n",
        "\n",
        "\n",
        "    ########## cutted ##########\n",
        "    # print(imagePath,'############################')\n",
        "    # plt.imshow(image)\n",
        "    # plt.show()\n",
        "    # cutted_image = cutImage(imagePath)\n",
        "    # (means, stds) = cv2.meanStdDev(cv2.cvtColor(cutted_image, cv2.COLOR_BGR2HSV))\n",
        "    # cutted_result = pd.DataFrame({'Mean_Blue': [means[0]], 'Mean_Green': [means[1]], 'Mean_Red': [means[2]], 'Standard_Blue': [stds[0]], 'Standard_Green': [stds[1]], 'Standard_Red': [stds[2]], 'Label': [make]})\n",
        "    # cutted_output = pd.concat([output, result], axis = 0)\n",
        "\n",
        "    # cutted_x_data = []\n",
        "    # for i in means:\n",
        "        # cutted_x_data.append(float(i))\n",
        "    # for i in stds:\n",
        "        # cutted_x_data.append(float(i))\n",
        "    # cutted_x_data = np.array(cutted_x_data)\n",
        "\n",
        "    # cutted_data = np.vstack((cutted_data, cutted_x_data))\n",
        "\n",
        "    #push label into label list\n",
        "    labels.append(make)\n",
        "\n",
        "data = np.array(data)\n",
        "cutted_data = np.array(cutted_data)\n",
        "\n",
        "clf = ensemble.DecisionTreeClassifier(n_estimators = 99)\n",
        "clf = clf.fit(data, labels)\n",
        "\n",
        "# cutted_clf = ensemble.RandomForestClassifier(n_estimators = 99)\n",
        "# cutted_clf = cutted_clf.fit(cutted_data, labels)\n",
        "\n",
        "correct = 0\n",
        "cutted_correct = 0\n",
        "num_test_data = 0\n",
        "\n",
        "tstart = time.time()\n",
        "\n",
        "while temp_data_num:\n",
        "\n",
        "    temp_data_num = temp_data_num - 1\n",
        "    # print(\"temp_data_num: \", temp_data_num)\n",
        "    imagePath = allimage_list.pop()\n",
        "    make = imagePath.split(\"/\")[-2]\n",
        "    num_test_data = num_test_data + 1\n",
        "\n",
        "    ########## original ##########\n",
        "    image = cv2.imread(imagePath)\n",
        "    (means, stds) = cv2.meanStdDev(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))\n",
        "    result = pd.DataFrame({'Mean_Blue': [means[0]], 'Mean_Green': [means[1]], 'Mean_Red': [means[2]], 'Standard_Blue': [stds[0]], 'Standard_Green': [stds[1]], 'Standard_Red': [stds[2]], 'Label': [make]})\n",
        "    output = pd.concat([output, result], axis = 0)\n",
        "\n",
        "    x_data = []\n",
        "    for i in means:\n",
        "        x_data.append(float(i))\n",
        "    for i in stds:\n",
        "        x_data.append(float(i))\n",
        "    x_data = np.array(x_data)\n",
        "    x_data = x_data.reshape(1,-1)\n",
        "    pred = clf.predict(x_data)\n",
        "\n",
        "    ########## cutted ##########\n",
        "    # cutted_image = cutImage(imagePath)\n",
        "    # (means, stds) = cv2.meanStdDev(cv2.cvtColor(cutted_image, cv2.COLOR_BGR2HSV))\n",
        "    # cutted_result = pd.DataFrame({'Mean_Blue': [means[0]], 'Mean_Green': [means[1]], 'Mean_Red': [means[2]], 'Standard_Blue': [stds[0]], 'Standard_Green': [stds[1]], 'Standard_Red': [stds[2]], 'Label': [make]})\n",
        "    # cutted_output = pd.concat([output, result], axis = 0)\n",
        "\n",
        "    # cutted_x_data = []\n",
        "    # for i in means:\n",
        "        # cutted_x_data.append(float(i))\n",
        "    # for i in stds:\n",
        "        # cutted_x_data.append(float(i))\n",
        "    # cutted_x_data = np.array(cutted_x_data)\n",
        "    # cutted_x_data = x_data.reshape(1,-1)\n",
        "    # cutted_pred = cutted_clf.predict(cutted_x_data)\n",
        "\n",
        "\n",
        "    #original result\t\n",
        "    # print(\"original\")\n",
        "    # print(\"target: \", make)\n",
        "    # print(\"predict: \", pred)\n",
        "\n",
        "    if make == pred:\n",
        "        correct = correct + 1\n",
        "\n",
        "    #cutted result\t\n",
        "    # print(\"cutted\")\n",
        "    # print(\"target: \", make)\n",
        "    # print(\"predict: \", cutted_pred)\n",
        "\n",
        "    # if make == cutted_pred:\n",
        "        # cutted_correct = cutted_correct + 1\n",
        "\n",
        "print(\"Original\")\n",
        "print(correct/num_test_data)\n",
        "# print(\"Cutted\")\n",
        "# print(cutted_correct/num_test_data)\n",
        "\n",
        "tend = time.time()\n",
        "\n",
        "print(\"time : \", total_data_num/(tend - tstart))\n",
        "\n",
        "output.to_csv('Output.csv')\n",
        "fig1 = plt.figure()\n",
        "ax1 = Axes3D(fig1)\n",
        "ax1.set_xlim3d(output['Mean_Blue'].min(), output['Mean_Blue'].max())\n",
        "ax1.set_ylim3d(output['Mean_Green'].min(), output['Mean_Green'].max())\n",
        "ax1.set_zlim3d(output['Mean_Red'].min(), output['Mean_Red'].max())\n",
        "for i in range(output.shape[0]):\n",
        "    if output.iloc[i]['Label'] == 'white':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'ro')\n",
        "    elif output.iloc[i]['Label'] == 'steak':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'go')\n",
        "    elif output.iloc[i]['Label'] == 'curl':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'bo')\n",
        "    elif output.iloc[i]['Label'] == 'dressed_long_leg':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'co')\n",
        "    elif output.iloc[i]['Label'] == 'long leg':\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'mo')\n",
        "    else:\n",
        "        ax1.plot(output.iloc[i]['Mean_Blue'], output.iloc[i]['Mean_Green'], output.iloc[i]['Mean_Red'], 'ko')\n",
        "plt.show()\n",
        "\n",
        "fig2 = plt.figure()\n",
        "ax2 = Axes3D(fig2)\n",
        "ax2.set_xlim3d(output['Standard_Blue'].min(), output['Standard_Blue'].max())\n",
        "ax2.set_ylim3d(output['Standard_Green'].min(), output['Standard_Green'].max())\n",
        "ax2.set_zlim3d(output['Standard_Red'].min(), output['Standard_Red'].max())\n",
        "for i in range(output.shape[0]):\n",
        "    if output.iloc[i]['Label'] == 'white':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'ro')\n",
        "    elif output.iloc[i]['Label'] == 'steak':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'go')\n",
        "    elif output.iloc[i]['Label'] == 'curl':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'bo')\n",
        "    elif output.iloc[i]['Label'] == 'dressed_long_leg':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'co')\n",
        "    elif output.iloc[i]['Label'] == 'long leg':\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'mo')\n",
        "    else:\n",
        "        ax2.plot(output.iloc[i]['Standard_Blue'], output.iloc[i]['Standard_Green'], output.iloc[i]['Standard_Red'], 'ko')\n",
        "plt.show()\n",
        "\n",
        "# cutted_output.to_csv('Cutted_Output.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-010387c2c053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mcutted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Mean_Blue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean_Green'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean_Red'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Blue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Green'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Red'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mcutted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Mean_Blue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean_Green'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean_Red'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Blue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Green'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard_Red'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6QaXT1oRA-R"
      },
      "source": [
        "# 4.gaussian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nr8z8hqRA-R",
        "outputId": "8b928721-51b1-4ab2-a334-5ac5b840726c"
      },
      "source": [
        "#載入必要模組\n",
        "from __future__ import print_function\n",
        "from sklearn.svm import SVC\n",
        "from skimage import exposure\n",
        "from skimage import feature\n",
        "from imutils import paths\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "from sklearn import tree\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import random\n",
        "import statistics\n",
        "import time\n",
        "#data用來存放HOG資訊，labels則是存放對應的標籤\n",
        "labels = []\n",
        "count = int(0)\n",
        "data = np.empty((0, 6),float)\n",
        "total_data_num = 0\n",
        "#依序讀取training dataset中的圖檔\n",
        "entries = os.listdir(\"train\")\n",
        "prediction = []\n",
        "allimage_list = []\n",
        "\n",
        "for dirPath in entries:\n",
        "    allimage = glob.glob( \"train/\"+dirPath +\"/*\")\n",
        "    label = 0\n",
        "    for i in allimage:\n",
        "        allimage_list.append(i)\n",
        "total_data_num = len(allimage_list)\n",
        "temp_data_num = total_data_num\n",
        "\n",
        "while temp_data_num > total_data_num * 0.3:\n",
        "\n",
        "        imagePath = allimage_list.pop(random.randint(0, temp_data_num - 1))\n",
        "        temp_data_num = temp_data_num - 1\n",
        "        #將資料夾的名稱取出作為該圖檔的標籤\n",
        "        make = imagePath.split(\"/\")[-1]\n",
        "        make = make.split(\"\\\\\")[-2]\n",
        "        if make == 'curl':\n",
        "            label = 1\n",
        "        elif make == 'dressed_long_leg':\n",
        "            label = 2\n",
        "        elif make == 'long leg':\n",
        "            label = 3\n",
        "        elif make == 'steak':\n",
        "            label =4\n",
        "        elif make == 'white':\n",
        "            label =5\n",
        "        elif make == 'small white':\n",
        "            label = 6\n",
        "\n",
        "        #----以下為訓練圖檔的預處理----# \n",
        "\n",
        "        #載入圖檔,轉為灰階,作模糊化處理\n",
        "        image = cv2.imread(imagePath)\n",
        "        (means, stds) = cv2.meanStdDev(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        #將裁切後的圖檔尺寸更改為500x500。\n",
        "        Cutted = cv2.resize(gray, (500, 500))\n",
        "        x_data = []\n",
        "        for i in means:\n",
        "            x_data.append(float(i))\n",
        "        for i in stds:\n",
        "            x_data.append(float(i))\n",
        "        x_data = np.array(x_data)\n",
        "\n",
        "        data = np.vstack((data, x_data))\n",
        "        labels.append(label)\n",
        "        count = count + 1\n",
        "        if count % 10 == 0:\n",
        "            print (count, end=\"\\r\")\n",
        "data = np.array(data)\n",
        "Gaussian = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
        "Gaussian.fit(data, labels)\n",
        "fps_list = []\n",
        "correct = 0\n",
        "num_test_data = 0\n",
        "while temp_data_num:\n",
        "    tstart = time.time()\n",
        "    temp_data_num = temp_data_num - 1\n",
        "    imagePath = allimage_list.pop()\n",
        "    make = imagePath.split(\"/\")[-1]\n",
        "    make = make.split(\"\\\\\")[-2]\n",
        "    # 從測試資料中讀取圖檔\n",
        "    image = cv2.imread(imagePath)\n",
        "    # ----以下為測試圖檔的預處理----# \n",
        "    # 轉為灰階並模糊化\n",
        "    (means, stds) = cv2.meanStdDev(cv2.cvtColor(image, cv2.COLOR_BGR2HSV))\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # 將裁切後的圖檔尺寸更改為500x500。\n",
        "    Cutted = cv2.resize(gray, (500, 500))\n",
        "\n",
        "    x_data = []\n",
        "    for i in means:\n",
        "        x_data.append(float(i))\n",
        "    for i in stds:\n",
        "        x_data.append(float(i))\n",
        "    # for i in H:\n",
        "        # x_data.append(float(i))\n",
        "    x_data = np.array(x_data)\n",
        "    x_data = x_data.reshape(1,-1)\n",
        "    pred = Gaussian.predict(x_data)\n",
        "    if pred < 1.5 and pred >= 0.5:\n",
        "        prediction = 'curl'\n",
        "    elif pred < 2.5 and pred >= 1.5:\n",
        "        prediction = 'dressed_long_leg'\n",
        "    elif pred < 3.5 and pred >= 2.5:\n",
        "        prediction = 'long leg'\n",
        "    elif pred < 4.5 and pred >= 3.5:\n",
        "        prediction = 'steak'\n",
        "    elif pred < 5.5 and pred >= 4.5:\n",
        "        prediction = 'white'\n",
        "    elif  pred < 6.5 and pred >= 5.5:\n",
        "        prediction = 'small white'\n",
        "\n",
        "    num_test_data = num_test_data + 1\n",
        "    if make == prediction:\n",
        "        correct = correct + 1\n",
        "    tend = time.time()\n",
        "    FPS_all = 1/(tend-tstart)\n",
        "    fps_list.append(FPS_all)\n",
        "mean = statistics.mean(fps_list)\n",
        "print(\"Average of FPS: \", mean)\n",
        "print(\"Accuracy: \", (correct/num_test_data)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a147e75fd5e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtotal_data_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#依序讀取training dataset中的圖檔\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mallimage_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train'"
          ]
        }
      ]
    }
  ]
}